# CompAss-Jason

This project provides another set of eyes for Niek Velduis' [Computational Assyriology project](https://github.com/niekveldhuis/CompAss). More specifically, it seeks to examine the relationship between the words used in lexical lists and other sumerian literature, which comprises chapter 3 of Niek Veldhuis' upcoming book. Information on this chapter is located [here](https://github.com/niekveldhuis/CompAss/blob/master/3_Vocabularies/3_Lexical_and_Literary_Vocabularies.md).

## Paritioning the Texts

The current work so far has determined the lexical connections between lexical lists and literary texts as a whole and has begun to examine the influence of specific lexical lists on specific non-lexical texts. This would consistute the first layer of partitioning, namely partitioning a single genre corpus into individual texts.

Additionally, a further layer of partitioning will be necessary, dividing individual texts (or more properly the words therein) into subsets of words. There are different dimensions by which this further partitioning can occur. Let's examine some paths:

1. Subsection of the Text
2. Frequency of Word
3. Complexity of Term

### 1. Subsection of the Text

The example given by Veldhuis about Lugal-e will be quite apt to demonstrate this. In this composition there is a subsection that enumerates stones. The question then becomes to what extent does the vocabulary of this section match the lexical list repertoire of stones. This too may also be found in a subsection of the lexical text OB Ura tablet 4.

### 2. Frequency of Word

Dividing the text by the terms general frequency may yield interesting results. One can compare the usage of the most frequent terms in both lexical and non-lexical texts.

### 3. Complexity of the Term

Here, I mean the singular lemma vs. multilemma expression that may appear in both lexical and non-lexical material.

## Motivation

When considering the overlap in language between lexical texts and other genres, it might be helpful to think about what conclusions we can draw when encountering different evidence. This section will discuss the possibilities we might encounter when examining the lexical overlap and consider the possible conclusions we might draw therefrom. Two values will be considered: the percentage of lexical entries that are found in the non-lexical text and the percentage of non-lexical entries found in the lexical text. Thus the possibilities will be broadly grouped into 4 types:

1. High matching in non-lexical text and high matching in lexical text
2. High matching in non-lexical text and low matching in lexical text
3. Low matching in non-lexical text and high matching in lexical text
4. Low matching in non-lexical text and low matching in lexical text

### 1. High in non-Lexical and High in Lexical

In this scenario, the number of matched terms nearly equals the total number of unique terms in both the non-lexical text and the lexical text. It would thus be tempting to conclude that one text was almost fully derived from the other. More specifically, the lexical list may have been drawn up from the words in that text as if the teacher was presenting the non-lexical text with a glossary of the terms, as one might see in modern times in grammar primers and crestomathies.

### 2. High in non-Lexical and Low in Lexical

Here, the number of matches nearly equal the totality of the terms in the non-Lexical text. We may conclude that a subset of the lexical list forms a sort of glossary for the text. What the nature of this subset is should be examined, especially considering the word block nature of some OB lexical lists like OB Ura, where each tablet consists of multiple semantic groupings. Hence, a further partitioning of the *lexical* text is necessary.

### 3. Low in non-Lexical and High in Lexical

A further partitioning of the *non-lexical* text is necessary.

### 4. Low in non-Lexical and Low in Lexical

This would tell us that there is little specific influence between the whole texts. However, there may be more to examine if one partitions both texts in question

## Things to think about

When regarding multilemma entries in OB lexical lists, do we confirm a match in another genre (literary texts) when we find those lemmas side by side and in the same order or in any order within the line (perhaps two lines)? If we do the former, we may miss examples where other words are placed in between the sequence or the sequence is in a different order, and thus under-match (EXAMPLE?). However, if we allow for a looser criterion for matching, we may find each of the lemmas in the same line but not synonymous with the lexical entry and thus over-match (EXAMPLE?).

## Note on precision and recall

When reading this section one might have considered that the concepts motivating the analysis are very similar to precision and recall. However, I decided not to use these terms because ...
